<!DOCTYPE html><html><head>
      <title>04.type_inference_stability</title>
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      
      <link rel="stylesheet" href="file:////home/tanvir/.vscode/extensions/shd101wyy.markdown-preview-enhanced-0.5.17/node_modules/@shd101wyy/mume/dependencies/katex/katex.min.css">
      
      
      
      
      
      
      
      
      
      <style>
      /* http://prismjs.com/download.html?themes=prism&languages=markup+css+clike+javascript+abap+actionscript+ada+apacheconf+apl+applescript+asciidoc+aspnet+autoit+autohotkey+bash+basic+batch+c+brainfuck+bro+bison+csharp+cpp+coffeescript+ruby+css-extras+d+dart+django+diff+docker+eiffel+elixir+erlang+fsharp+fortran+gherkin+git+glsl+go+graphql+groovy+haml+handlebars+haskell+haxe+http+icon+inform7+ini+j+jade+java+jolie+json+julia+keyman+kotlin+latex+less+livescript+lolcode+lua+makefile+markdown+matlab+mel+mizar+monkey+nasm+nginx+nim+nix+nsis+objectivec+ocaml+oz+parigp+parser+pascal+perl+php+php-extras+powershell+processing+prolog+properties+protobuf+puppet+pure+python+q+qore+r+jsx+reason+rest+rip+roboconf+crystal+rust+sas+sass+scss+scala+scheme+smalltalk+smarty+sql+stylus+swift+tcl+textile+twig+typescript+vbnet+verilog+vhdl+vim+wiki+xojo+yaml */
/**
 * prism.js default theme for JavaScript, CSS and HTML
 * Based on dabblet (http://dabblet.com)
 * @author Lea Verou
 */

code[class*="language-"],
pre[class*="language-"] {
	color: black;
	background: none;
	text-shadow: 0 1px white;
	font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
	text-align: left;
	white-space: pre;
	word-spacing: normal;
	word-break: normal;
	word-wrap: normal;
	line-height: 1.5;

	-moz-tab-size: 4;
	-o-tab-size: 4;
	tab-size: 4;

	-webkit-hyphens: none;
	-moz-hyphens: none;
	-ms-hyphens: none;
	hyphens: none;
}

pre[class*="language-"]::-moz-selection, pre[class*="language-"] ::-moz-selection,
code[class*="language-"]::-moz-selection, code[class*="language-"] ::-moz-selection {
	text-shadow: none;
	background: #b3d4fc;
}

pre[class*="language-"]::selection, pre[class*="language-"] ::selection,
code[class*="language-"]::selection, code[class*="language-"] ::selection {
	text-shadow: none;
	background: #b3d4fc;
}

@media print {
	code[class*="language-"],
	pre[class*="language-"] {
		text-shadow: none;
	}
}

/* Code blocks */
pre[class*="language-"] {
	padding: 1em;
	margin: .5em 0;
	overflow: auto;
}

:not(pre) > code[class*="language-"],
pre[class*="language-"] {
	background: #f5f2f0;
}

/* Inline code */
:not(pre) > code[class*="language-"] {
	padding: .1em;
	border-radius: .3em;
	white-space: normal;
}

.token.comment,
.token.prolog,
.token.doctype,
.token.cdata {
	color: slategray;
}

.token.punctuation {
	color: #999;
}

.namespace {
	opacity: .7;
}

.token.property,
.token.tag,
.token.boolean,
.token.number,
.token.constant,
.token.symbol,
.token.deleted {
	color: #905;
}

.token.selector,
.token.attr-name,
.token.string,
.token.char,
.token.builtin,
.token.inserted {
	color: #690;
}

.token.operator,
.token.entity,
.token.url,
.language-css .token.string,
.style .token.string {
	color: #a67f59;
	background: hsla(0, 0%, 100%, .5);
}

.token.atrule,
.token.attr-value,
.token.keyword {
	color: #07a;
}

.token.function {
	color: #DD4A68;
}

.token.regex,
.token.important,
.token.variable {
	color: #e90;
}

.token.important,
.token.bold {
	font-weight: bold;
}
.token.italic {
	font-style: italic;
}

.token.entity {
	cursor: help;
}

/* highlight */
pre[data-line] {
	position: relative;
	padding: 1em 0 1em 3em;
  }
  pre[data-line] .line-highlight-wrapper {
	position: absolute;
	top: 0;
	left: 0;
	background-color: transparent;
	display: block;
	width: 100%;
  }
  
  pre[data-line] .line-highlight {
	position: absolute;
	left: 0;
	right: 0;
	padding: inherit 0;
	margin-top: 1em;
	background: hsla(24, 20%, 50%,.08);
	background: linear-gradient(to right, hsla(24, 20%, 50%,.1) 70%, hsla(24, 20%, 50%,0));
	pointer-events: none;
	line-height: inherit;
	white-space: pre;
  }
  
  pre[data-line] .line-highlight:before, 
  pre[data-line] .line-highlight[data-end]:after {
	content: attr(data-start);
	position: absolute;
	top: .4em;
	left: .6em;
	min-width: 1em;
	padding: 0 .5em;
	background-color: hsla(24, 20%, 50%,.4);
	color: hsl(24, 20%, 95%);
	font: bold 65%/1.5 sans-serif;
	text-align: center;
	vertical-align: .3em;
	border-radius: 999px;
	text-shadow: none;
	box-shadow: 0 1px white;
  }
  
  pre[data-line] .line-highlight[data-end]:after {
	content: attr(data-end);
	top: auto;
	bottom: .4em;
  }@font-face{font-family:'Roboto Mono';font-style:normal;font-weight:400;src:local('Roboto Mono'),local('RobotoMono-Regular'),url(https://fonts.gstatic.com/s/robotomono/v7/L0x5DF4xlVMF-BfR8bXMIjhLq3o.ttf) format('truetype')}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:300;src:local('Source Sans Pro Light'),local('SourceSansPro-Light'),url(https://fonts.gstatic.com/s/sourcesanspro/v13/6xKydSBYKcSV-LCoeQqfX1RYOo3ik4zwlxdr.ttf) format('truetype')}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:400;src:local('Source Sans Pro Regular'),local('SourceSansPro-Regular'),url(https://fonts.gstatic.com/s/sourcesanspro/v13/6xK3dSBYKcSV-LCoeQqfX1RYOo3qOK7g.ttf) format('truetype')}@font-face{font-family:'Source Sans Pro';font-style:normal;font-weight:600;src:local('Source Sans Pro SemiBold'),local('SourceSansPro-SemiBold'),url(https://fonts.gstatic.com/s/sourcesanspro/v13/6xKydSBYKcSV-LCoeQqfX1RYOo3i54rwlxdr.ttf) format('truetype')}*{-webkit-font-smoothing:antialiased;-webkit-overflow-scrolling:touch;-webkit-tap-highlight-color:rgba(0,0,0,0);-webkit-text-size-adjust:none;-webkit-touch-callout:none;box-sizing:border-box}body:not(.ready){overflow:hidden}body:not(.ready) .app-nav,body:not(.ready)>nav,body:not(.ready) [data-cloak]{display:none}div#app{font-size:30px;font-weight:lighter;margin:40vh auto;text-align:center}div#app:empty:before{content:"Loading..."}.emoji{height:19.2px;height:1.2rem;vertical-align:middle}.progress{background-color:#42b983;background-color:var(--theme-color, #42b983);height:2px;left:0;position:fixed;right:0;top:0;transition:width .2s,opacity .4s;width:0;z-index:5}.search .search-keyword,.search a:hover{color:#42b983;color:var(--theme-color, #42b983)}.search .search-keyword{font-style:normal;font-weight:700}body,html{height:100%}body{-moz-osx-font-smoothing:grayscale;-webkit-font-smoothing:antialiased;color:#34495e;font-family:Source Sans Pro,Helvetica Neue,Arial,sans-serif;font-size:15px;letter-spacing:0;margin:0;overflow-x:hidden}img{max-width:100%}a[disabled]{cursor:not-allowed;opacity:.6}kbd{color:#34495e;border:1px solid #ccc;border-radius:3px;display:inline-block;font-size:12px !important;line-height:12px;margin-bottom:3px;padding:3px 5px;vertical-align:middle}.task-list-item{list-style-type:none}li input[type=checkbox]{margin:0 .2em .25em -1.6em;vertical-align:middle}.app-nav{left:0;margin:25px 60px 0 0;position:absolute;right:0;text-align:right;z-index:2}.app-nav p{margin:0}.app-nav>a{margin:0 16px;margin:0 1rem;padding:5px 0}.app-nav li,.app-nav ul{display:inline-block;list-style:none;margin:0}.app-nav a{color:inherit;font-size:16px;text-decoration:none;transition:color .3s}.app-nav a.active,.app-nav a:hover{color:#42b983;color:var(--theme-color, #42b983)}.app-nav a.active{border-bottom:2px solid #42b983;border-bottom:2px solid var(--theme-color, #42b983)}.app-nav li{display:inline-block;margin:0 16px;margin:0 1rem;padding:5px 0;position:relative}.app-nav li ul{background-color:#fff;border:1px solid #ddd;border-bottom-color:#ccc;border-radius:4px;box-sizing:border-box;display:none;max-height:calc(100vh - 61px);overflow-y:scroll;padding:10px 0;position:absolute;right:-15px;text-align:left;top:100%;white-space:nowrap}.app-nav li ul li{display:block;font-size:14px;line-height:16px;line-height:1rem;margin:0;margin:8px 14px;white-space:nowrap}.app-nav li ul a{display:block;font-size:inherit;margin:0;padding:0}.app-nav li ul a.active{border-bottom:0}.app-nav li:hover ul{display:block}.app-nav.no-badge{margin-right:25px}.github-corner{border-bottom:0;position:fixed;right:0;text-decoration:none;top:0;z-index:1}.github-corner svg{color:#fff;fill:#42b983;fill:var(--theme-color, #42b983);height:80px;width:80px}.github-corner:hover .octo-arm{-webkit-animation:a .56s ease-in-out;animation:a .56s ease-in-out}main{display:block;position:relative;width:100vw;height:100%;z-index:0}.anchor{display:inline-block;text-decoration:none;transition:all .3s}.anchor span{color:#34495e}.anchor:hover{text-decoration:underline}.sidebar{border-right:1px solid rgba(0,0,0,0.07);overflow-y:auto;padding:40px 0 0;top:0;bottom:0;left:0;position:absolute;transition:-webkit-transform .25s ease-out;transition:transform .25s ease-out;transition:transform .25s ease-out,-webkit-transform .25s ease-out;width:300px;z-index:3}.sidebar>h1{margin:0 auto 16px;margin:0 auto 1rem;font-size:24px;font-size:1.5rem;font-weight:300;text-align:center}.sidebar>h1 a{color:inherit;text-decoration:none}.sidebar>h1 .app-nav{display:block;position:static}.sidebar .sidebar-nav{line-height:2em;padding-bottom:40px}.sidebar ul{margin:0;padding:0}.sidebar li>p{font-weight:700;margin:0}.sidebar ul,.sidebar ul li{list-style:none}.sidebar ul li a{border-bottom:none;display:block}.sidebar ul li ul{padding-left:20px}.sidebar::-webkit-scrollbar{width:4px}.sidebar::-webkit-scrollbar-thumb{background:transparent;border-radius:4px}.sidebar:hover::-webkit-scrollbar-thumb{background:hsla(0,0%,53%,0.4)}.sidebar:hover::-webkit-scrollbar-track{background:hsla(0,0%,53%,0.1)}.sidebar-toggle{background-color:transparent;background-color:hsla(0,0%,100%,0.8);border:0;outline:none;padding:10px;bottom:0;left:0;position:absolute;text-align:center;transition:opacity .3s;width:30px;width:284px;z-index:4}.sidebar-toggle .sidebar-toggle-button:hover{opacity:.4}.sidebar-toggle span{background-color:#42b983;background-color:var(--theme-color, #42b983);display:block;margin-bottom:4px;width:16px;height:2px}body.sticky .sidebar,body.sticky .sidebar-toggle{position:fixed}.content{padding-top:60px;top:0;right:0;bottom:0;left:300px;position:absolute;transition:left .25s ease}.markdown-preview>*{box-sizing:border-box;font-size:inherit}.markdown-preview>:first-child{margin-top:0 !important}.markdown-preview hr{border:none;border-bottom:1px solid #eee;margin:2em 0}.markdown-preview table{border-collapse:collapse;border-spacing:0;display:block;margin-bottom:16px;margin-bottom:1rem;overflow:auto;width:100%}.markdown-preview th{font-weight:700}.markdown-preview td,.markdown-preview th{border:1px solid #ddd;padding:6px 13px}.markdown-preview tr{border-top:1px solid #ccc}.markdown-preview p.tip,.markdown-preview tr:nth-child(2n){background-color:#f8f8f8}.markdown-preview p.tip{border-bottom-right-radius:2px;border-left:4px solid #f66;border-top-right-radius:2px;margin:2em 0;padding:12px 24px 12px 30px;position:relative}.markdown-preview p.tip code{background-color:#efefef}.markdown-preview p.tip em{color:#34495e}.markdown-preview p.tip:before{background-color:#f66;border-radius:100%;color:#fff;content:"!";font-family:Dosis,Source Sans Pro,Helvetica Neue,Arial,sans-serif;font-size:14px;font-weight:700;left:-12px;line-height:20px;position:absolute;width:20px;height:20px;text-align:center;top:14px}.markdown-preview p.warn{background:rgba(66,185,131,0.1);border-radius:2px;padding:16px;padding:1rem}body.close .sidebar{-webkit-transform:translateX(-300px);transform:translateX(-300px)}body.close .sidebar-toggle{width:auto}body.close .content{left:0}@media print{.app-nav,.github-corner,.sidebar,.sidebar-toggle{display:none}}@media screen and (max-width:768px){.github-corner,.sidebar,.sidebar-toggle{position:fixed}.app-nav{margin-top:16px}.app-nav li ul{top:30px}main{height:auto;overflow-x:hidden}.sidebar{left:-300px;transition:-webkit-transform .25s ease-out;transition:transform .25s ease-out;transition:transform .25s ease-out,-webkit-transform .25s ease-out}.content{left:0;max-width:100vw;position:static;padding-top:20px;transition:-webkit-transform .25s ease;transition:transform .25s ease;transition:transform .25s ease,-webkit-transform .25s ease}.app-nav,.github-corner{transition:-webkit-transform .25s ease-out;transition:transform .25s ease-out;transition:transform .25s ease-out,-webkit-transform .25s ease-out}.sidebar-toggle{background-color:transparent;width:auto;padding:30px 30px 10px 10px}body.close .sidebar{-webkit-transform:translateX(300px);transform:translateX(300px)}body.close .sidebar-toggle{background-color:hsla(0,0%,100%,0.8);transition:background-color 1s;width:284px;padding:10px}body.close .content{-webkit-transform:translateX(300px);transform:translateX(300px)}body.close .app-nav,body.close .github-corner{display:none}.github-corner .octo-arm{-webkit-animation:a .56s ease-in-out;animation:a .56s ease-in-out}.github-corner:hover .octo-arm{-webkit-animation:none;animation:none}}@-webkit-keyframes a{0%,to{-webkit-transform:rotate(0);transform:rotate(0)}20%,60%{-webkit-transform:rotate(-25deg);transform:rotate(-25deg)}40%,80%{-webkit-transform:rotate(10deg);transform:rotate(10deg)}}@keyframes a{0%,to{-webkit-transform:rotate(0);transform:rotate(0)}20%,60%{-webkit-transform:rotate(-25deg);transform:rotate(-25deg)}40%,80%{-webkit-transform:rotate(10deg);transform:rotate(10deg)}}section.cover{-webkit-box-align:center;-ms-flex-align:center;align-items:center;background-position:50%;background-repeat:no-repeat;background-size:cover;height:100vh;display:none}section.cover .cover-main{-webkit-box-flex:1;-ms-flex:1;flex:1;margin:-20px 16px 0;text-align:center;z-index:1}section.cover a{color:inherit}section.cover a,section.cover a:hover{text-decoration:none}section.cover p{line-height:24px;line-height:1.5rem;margin:1em 0}section.cover h1{color:inherit;font-size:40px;font-size:2.5rem;font-weight:300;margin:10px 0 40px;margin:.625rem 0 2.5rem;position:relative;text-align:center}section.cover h1 a{display:block}section.cover h1 small{bottom:-7px;bottom:-0.4375rem;font-size:16px;font-size:1rem;position:absolute}section.cover blockquote{font-size:24px;font-size:1.5rem;text-align:center}section.cover ul{line-height:1.8;list-style-type:none;margin:1em auto;max-width:500px;padding:0}section.cover .cover-main>p:last-child a{border-color:#42b983;border:1px solid var(--theme-color, #42b983);border-radius:2rem;box-sizing:border-box;color:#42b983;color:var(--theme-color, #42b983);display:inline-block;font-size:16.8px;font-size:1.05rem;letter-spacing:1.6px;letter-spacing:.1rem;margin-right:16px;margin-right:1rem;padding:.75em 32px;padding:.75em 2rem;text-decoration:none;transition:all .15s ease}section.cover .cover-main>p:last-child a:last-child{background-color:#42b983;background-color:var(--theme-color, #42b983);color:#fff;margin-right:0}section.cover .cover-main>p:last-child a:last-child:hover{color:inherit;opacity:.8}section.cover .cover-main>p:last-child a:hover{color:inherit}section.cover blockquote>p>a{border-bottom:2px solid #42b983;border-bottom:2px solid var(--theme-color, #42b983);transition:color .3s}section.cover blockquote>p>a:hover{color:#42b983;color:var(--theme-color, #42b983)}section.cover.show{display:-webkit-box;display:-ms-flexbox;display:flex}section.cover.has-mask .mask{background-color:#fff;opacity:.8;position:absolute;width:100%;height:100%}.sidebar,body{background-color:#fff}.sidebar{color:#364149}.sidebar li{margin:6px 0 6px 15px}.sidebar ul li a{color:#505d6b;font-size:14px;font-weight:400;overflow:hidden;text-decoration:none;text-overflow:ellipsis;white-space:nowrap}.sidebar ul li a:hover{text-decoration:underline}.sidebar ul li ul{padding:0}.sidebar ul li.active>a{border-right:2px solid;color:#42b983;color:var(--theme-color, #42b983);font-weight:600}.app-sub-sidebar li:before{content:"-";padding-right:4px;float:left}.markdown-preview h1,.markdown-preview h2,.markdown-preview h3,.markdown-preview h4,.markdown-preview strong{color:#2c3e50;font-weight:600}.markdown-preview a{color:#42b983;color:var(--theme-color, #42b983);font-weight:600}.md-sidebar-toc a{color:#42b983;font-weight:600}.markdown-preview h1{font-size:32px;font-size:2rem;margin:0 0 16px;margin:0 0 1rem}.markdown-preview h2{font-size:28px;font-size:1.75rem;margin:45px 0 12.8px;margin:45px 0 .8rem}.markdown-preview h3{font-size:24px;font-size:1.5rem;margin:40px 0 9.6px;margin:40px 0 .6rem}.markdown-preview h4{font-size:20px;font-size:1.25rem}.markdown-preview h5,.markdown-preview h6{font-size:16px;font-size:1rem}.markdown-preview h6{color:#777}.markdown-preview figure,.markdown-preview p{margin:1.2em 0}.markdown-preview ol,.markdown-preview p,.markdown-preview ul{line-height:25.6px;line-height:1.6rem;word-spacing:.8px;word-spacing:.05rem}.markdown-preview ol,.markdown-preview ul{padding-left:24px;padding-left:1.5rem}.markdown-preview blockquote{border-left:4px solid #42b983;border-left:4px solid var(--theme-color, #42b983);color:#858585;background-color:#f0f0f0;margin:2em 0;padding-left:20px}.markdown-preview blockquote p{font-weight:600;margin-left:0}.markdown-preview iframe{margin:1em 0}.markdown-preview em{color:#7f8c8d}.markdown-preview{width:100%;height:100%;box-sizing:border-box}.markdown-preview .pagebreak,.markdown-preview .newpage{page-break-before:always}.markdown-preview pre.line-numbers{position:relative;padding-left:3.8em;counter-reset:linenumber}.markdown-preview pre.line-numbers>code{position:relative}.markdown-preview pre.line-numbers .line-numbers-rows{position:absolute;pointer-events:none;top:1em;font-size:100%;left:0;width:3em;letter-spacing:-1px;border-right:1px solid #999;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.markdown-preview pre.line-numbers .line-numbers-rows>span{pointer-events:none;display:block;counter-increment:linenumber}.markdown-preview pre.line-numbers .line-numbers-rows>span:before{content:counter(linenumber);color:#999;display:block;padding-right:.8em;text-align:right}.markdown-preview .mathjax-exps .MathJax_Display{text-align:center !important}.markdown-preview:not([for="preview"]) .code-chunk .btn-group{display:none}.markdown-preview:not([for="preview"]) .code-chunk .status{display:none}.markdown-preview:not([for="preview"]) .code-chunk .output-div{margin-bottom:16px}.scrollbar-style::-webkit-scrollbar{width:8px}.scrollbar-style::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}.scrollbar-style::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,0.66);border:4px solid rgba(150,150,150,0.66);background-clip:content-box}html body[for="html-export"]:not([data-presentation-mode]){position:relative;width:100%;height:100%;top:0;left:0;margin:0;padding:0;overflow:auto}html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{position:relative;top:0}@media screen and (min-width:914px){html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{padding:2em calc(50% - 457px + 2em)}}@media screen and (max-width:914px){html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{font-size:14px !important;padding:1em}}@media print{html body[for="html-export"]:not([data-presentation-mode]) #sidebar-toc-btn{display:none}}html body[for="html-export"]:not([data-presentation-mode]) #sidebar-toc-btn{position:fixed;bottom:8px;left:8px;font-size:28px;cursor:pointer;color:inherit;z-index:99;width:32px;text-align:center;opacity:.4}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] #sidebar-toc-btn{opacity:1}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc{position:fixed;top:0;left:0;width:300px;height:100%;padding:32px 0 48px 0;font-size:14px;box-shadow:0 0 4px rgba(150,150,150,0.33);box-sizing:border-box;overflow:auto;background-color:inherit}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar{width:8px}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,0.66);border:4px solid rgba(150,150,150,0.66);background-clip:content-box}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc a{text-decoration:none}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc ul{padding:0 1.6em;margin-top:.8em}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc li{margin-bottom:.8em}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc ul{list-style-type:none}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{left:300px;width:calc(100% -  300px);padding:2em calc(50% - 457px -  150px);margin:0;box-sizing:border-box}@media screen and (max-width:1274px){html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{width:100%}}html body[for="html-export"]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .markdown-preview{left:50%;transform:translateX(-50%)}html body[for="html-export"]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .md-sidebar-toc{display:none}
/* Please visit the URL below for more information: */
/*   https://shd101wyy.github.io/markdown-preview-enhanced/#/customize-css */
.markdown-preview.markdown-preview {
  color: rgba(0, 0, 0, 0.712);
}
.markdown-preview.markdown-preview .markdown-preview a:hover {
  color: blue;
  text-decoration: underline;
}
.markdown-preview.markdown-preview pre[data-role="codeBlock"] {
  font-size: 13px !important;
  background-color: whitesmoke;
}
.markdown-preview.markdown-preview h1 {
  color: #116062;
  font-size: 40px;
  font-weight: 50;
  margin-bottom: -6px;
  margin-top: -6px;
  font-family: "Anton";
  font-style: italic;
}
.markdown-preview.markdown-preview h2 {
  color: #020202;
  font-size: 20px;
  margin-bottom: 0px;
  margin-top: 0px;
  font-family: "Microsoft Yahei";
  font-style: italic;
}
.markdown-preview.markdown-preview h3 {
  color: #020202;
  font-size: 15px;
  margin-bottom: 0px;
  margin-top: 0px;
  font-family: "Microsoft Yahei";
  font-style: normal;
}
.markdown-preview.markdown-preview code {
  color: rgba(110, 5, 5, 0.739);
  font-weight: 550;
}
.markdown-preview.markdown-preview blockquote {
  margin-bottom: 40px;
  margin-top: 30px;
  background-color: #ffffff;
  padding: 0.3px;
  padding-left: 5px;
}
.markdown-preview.markdown-preview blockquote p {
  color: #5f0303;
  font-size: 14px;
  font-family: "Microsoft Yahei";
  font-style: italic;
  font-weight: 100;
  line-height: 1.5;
}
@media print {
  .markdown-preview.markdown-preview {
    font-size: 18px;
  }
}

      </style>
    </head>
    <body for="html-export">
      <div class="mume markdown-preview  ">
      <p><a id="julia_basics" href></a></p>
<div id="juiacourse" style="text-align:right;">
        <a href title>
                <img style="border-radius: 10px 50px;" height="70" width="140" src="../other_files/julia-2.jpg" alt="julalogo">
        </a>
</div>
<h1 class="mume-header" id="04-type-inference-type-stability-and-so-on">04. Type inference, type stability and so on</h1>

<blockquote>
<p>It is believed that if you want programmer productivity, you should use a <strong>dynamic language</strong>, such as Python, or R. On the other hand, if you want fast code execution, you should use a <strong>statically typed language</strong>, such as C or Java.</p>
</blockquote>
<ul>
<li>
<p>A language is statically-typed if the type of a variable is known at compile-time instead of at run-time.</p>
</li>
<li>
<p>In Statically typed languages, once a variable has been declared with a type, it cannot ever be assigned to some other variable of different type and doing so will raise a type error at compile-time(some IDE&#x2019;s generally shows a Red Cross mark denoting the error).</p>
</li>
<li>
<p>Static typing usually results in compiled code that executes more quickly because when the compiler knows the exact data types that are in use, it can produce optimized machine code (i.e. faster and/or using less memory).</p>
</li>
<li>
<p>A language is <strong>dynamically-typed</strong> if the type of a variable is checked during run-time.</p>
</li>
<li>
<p>In dynamically typed languages, variables are bound to objects at run-time by means of assignment statements, and it is possible to bind the same variables to objects of different types during the execution of the program.</p>
</li>
<li>
<p>Dynamic type checking typically results in less optimized code than static type checking. It also includes the possibility of run time type errors and forces run time checks to occur for every execution of the program
This is something that is especially prominent in scientific computing. This is the situation where the performance-critical inner kernel is written in C, but is then wrapped and used from a dynamic, higher-level language. Code written in traditional, scientific computing environments such as R, Matlab, or NumPy follows this paradigm.</p>
</li>
</ul>
<p>Code written in this fashion is not without its drawbacks, however. Even though it looks like it gets you the best of both worlds&#x2014;fast computation, while allowing the programmer to use a high-level language&#x2014;this is a path full of hidden dangers. For one, someone will have to write the low-level kernel. So, you need two different skill sets. If you are lucky enough to find the low-level code in C for your project, you are fine. However, if you are doing anything new or original, or even slightly different from the norm, you will find yourself writing both C and a high-level language. This will severely limit the number of contributors that your projects or research will get: to be really productive, those contributors really have to be familiar with two languages.</p>
<p>Secondly, when running code routinely written in two languages, there can be severe and unforeseen performance pitfalls. When you can drop down to C code quickly, everything is fine. However, if, for time reasons, effort, skill or changing requirements, you cannot write a performance-intensive part of your algorithm in C, you&apos;ll find your program taking hundreds or even thousands of times longer than you expected.</p>
<blockquote>
<p>Julia is the first modern language to make a reasonable effort to solve the two-language problem. It is a high-level, dynamic language with powerful features that make for very productive programming. At the same time, code written in Julia usually runs very quickly, almost as quickly as code written in statically typed languages</p>
</blockquote>
<h2 class="mume-header" id="julias-type-inference-and-the-compiler">Julia&apos;s Type Inference and the Compiler</h2>

<p>Julia is a Just In Time (JIT) compiled language, rather than an interpreted one in which the code in a high-level language is converted to machine code for execution on the CPU at runtime. This allows Julia to be dynamic, without having the overhead of interpretation. However, Julia is fast not because it is JIT compiled. <em>One can write very slow code in Julia but it&apos;s still JIT compiled! Instead, the reason why Julia is fast is because, roughly it is the combination of the following two ideas:</em></p>
<ul>
<li>Type inference (this allows to write a generic code but still get the types correct)</li>
<li>Type specialization in functions (picking the correct method so that you get C like performance!)</li>
</ul>
<h2 class="mume-header" id="about-c-and-python">About C and Python</h2>

<p>We spent quite a good amount of time explaining some stuffs at the core level of the computer, and sort of explained why everything needs to have a type in computer. Some languages are more explicit about types, while others try to hide the types from the user. A type tells the compiler how to store and <strong>interpret</strong> the memory of a value. When you have a slab of memory of bits, you have to know what the bits mean. Importantly, it will know <em>what to do for function calls</em>. If the code tells it to add two floating point numbers, it will send them as inputs to somewhere which will give instructions to carry out operations on floating-point numbers. However if the types are not known, it cannot be actually computed until the types are fully known, since otherwise it&apos;s impossible to interpret the memory and understand how to operate.</p>
<p>In languages like C, the programmer has to declare the types of variables in the program. Here is a <strong>sample code for C</strong>,</p>
<pre data-role="codeBlock" data-info="C" class="language-c"><span class="token keyword">void</span> <span class="token function">add</span><span class="token punctuation">(</span><span class="token keyword">double</span> <span class="token operator">*</span>a<span class="token punctuation">,</span> <span class="token keyword">double</span> <span class="token operator">*</span>b<span class="token punctuation">,</span> <span class="token keyword">double</span> <span class="token operator">*</span>c<span class="token punctuation">,</span> <span class="token class-name">size_t</span> n<span class="token punctuation">)</span><span class="token punctuation">{</span>
  <span class="token class-name">size_t</span> i<span class="token punctuation">;</span>
  <span class="token keyword">for</span><span class="token punctuation">(</span>i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> n<span class="token punctuation">;</span> <span class="token operator">++</span>i<span class="token punctuation">)</span> <span class="token punctuation">{</span>
    c<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> a<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">+</span> b<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">;</span>
    <span class="token comment">// val = a[i] + b[i]; ## put them in stack</span>
    <span class="token comment">// c[i] = val </span>

  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</pre><p>The types are known at compile time because the programmer tells what are the types of everything. In C, for compiler it is possible to know all of the different sizes because you tell it exactly what the types are for everything. Therefore, it&apos;s enabled to optimize with type information.</p>
<p>In many interpreted languages like Python, types are checked at runtime. So when we do the <strong>same thing in Python</strong></p>
<pre data-role="codeBlock" data-info="Python" class="language-python">a<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">2</span> <span class="token comment">## it creates a ponter</span>
b<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">4</span> <span class="token comment">## it creates another pointer</span>
a <span class="token operator">+</span> b
</pre><p>when the addition occurs, the Python interpreter will check the object holding the values and ask it for its types, and use those types to know how to compute the <code>+</code> function. For this reason, the add function in Python is rather complex since it needs to decode and have a version for all primitive types! Not only is there runtime overhead checks in function calls due to not being explicit about types, there is also a memory overhead since it is impossible to know how much memory a value with take since that&apos;s a property of its type. Thus the Python interpreter cannot statically guerentee exact unchanging values for the size that a value would take in the stack, meaning that the variables are not stack-allocated. This means that every number ends up heap-allocated, which hopefully begins to explain why this is not as fast as C.</p>
<h2 class="mume-header" id="julias-solution">Julia&apos;s solution</h2>

<p>Julia is somewhat of a hybrid. For C, if you say <code>a</code> is going you a vector 64-bit floating point numbers and try to put something that is 128-bit object it will just fail. But Python is in the whole other direction where it is equipped to change its type anytime because in any case  whenever it&apos;s doing a function call it&apos;s going to check what the type it has, so it&apos;s not strictly necessary to have the type information at the begining. So it&apos;s okay to keep on changing your types around. That check will cost something but it will know how to handle these type changes whereas the C function will not. Julia kind of falls in the middle. That is the tradeoff between flexibility vs. proper memory management. WHat happened in julia, Types in Julia are also optional when writing. For example, we can write the following</p>
<pre data-role="codeBlock" data-info="julia" class="language-julia"><span class="token comment"># code chunk 1</span>
a <span class="token operator">=</span> <span class="token number">2</span>
b <span class="token operator">=</span> <span class="token number">4</span>
a <span class="token operator">+</span> b 
</pre><p>that looks same as Python version. When this code is running on REPL, it will do something similar to Python because it cannot know when you change the type of the variables  beforehand. But here is what the ncie thing happened in Julia, before JIT compilation, Julia runs a <strong>type inference algorithm which will try to find out that</strong> <code>a</code> is an <code>Int</code>, and <code>b</code> is an <code>Int</code> before run time. Moreover the type of  <code>a+b</code> is deduced as an <code>Int</code> based on type of the variables, again before run time. We can see the type inference step using the macro <code>@code_typed</code></p>
<pre data-role="codeBlock" data-info="julia" class="language-julia"><span class="token comment"># code chunk 2</span>
<span class="token comment"># we will use @code_typed macro</span>

f1<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token operator">=</span> <span class="token number">2</span>x


julia<span class="token operator">&gt;</span> f1<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token operator">=</span> <span class="token number">2</span>x
<span class="token comment"># f1 (generic function with 1 method)</span>

julia<span class="token operator">&gt;</span> @code_typed f1<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span>
<span class="token comment"># CodeInfo(</span>
<span class="token comment"># 1 &#x2500; %1 = Base.mul_int(2, x)::Int64</span>
<span class="token comment"># &#x2514;&#x2500;&#x2500;      return %1</span>
<span class="token comment"># ) =&gt; Int64</span>
</pre><p>The <code>Int64</code> is the important part, in this it immediately sees the types because it is easy to infer the types, and then it will specialize. So when a functions is invoked, Julia will check the types of the variable, but when it enters the function, it will start to deduce what&apos;s going on with the type of the objects it contains. Let&apos;s have a closer look on how type inference plays a role when a function is invoked.</p>
<h2 class="mume-header" id="type-specialization-in-functions">Type Specialization in Functions</h2>

<p>Now we can actually see what happens in the type specialization phase. All this means is we know the types now and then LLVM (low level virtual machine) compiler and specializes the code for a specific type</p>
<pre data-role="codeBlock" data-info="julia" class="language-julia">julia<span class="token operator">&gt;</span> @code_llvm f1<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span>

<span class="token comment"># ;  @ REPL[5]:1 within `f1&apos;</span>
<span class="token comment"># define i64 @julia_f1_839(i64) {</span>
<span class="token comment"># top:</span>
<span class="token comment"># ; &#x250C; @ int.jl:87 within `*&apos;</span>
<span class="token comment">#    %1 = shl i64 %0, 1</span>
<span class="token comment"># ; &#x2514;</span>
<span class="token comment">#   ret i64 %1</span>
<span class="token comment"># }</span>
</pre><p>Notice this only works for <code>64</code> bit integer. What happens if we give a floar</p>
<pre data-role="codeBlock" data-info="julia" class="language-julia"><span class="token comment">#  @code_llvm f1(2.0)</span>

<span class="token comment">#  ;  @ REPL[5]:1 within `f1&apos;</span>
<span class="token comment"># define double @julia_f1_841(double) {</span>
<span class="token comment"># top:</span>
<span class="token comment"># ; &#x250C; @ promotion.jl:312 within `*&apos; @ float.jl:405</span>
<span class="token comment">#    %1 = fmul double %0, 2.000000e+00</span>
<span class="token comment"># ; &#x2514;</span>
<span class="token comment">#   ret double %1</span>
<span class="token comment"># }</span>
</pre><p>Now it is for double. And this is  <code>type specialization</code> in action. Now finally what we have seen yesterday,</p>
<pre data-role="codeBlock" data-info="julia" class="language-julia">foo<span class="token punctuation">(</span>x <span class="token punctuation">,</span> y<span class="token punctuation">)</span> <span class="token operator">=</span> x <span class="token operator">+</span> y

julia<span class="token operator">&gt;</span> @code_llvm foo<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3.0</span><span class="token punctuation">)</span> 

<span class="token comment"># ;  @ REPL[11]:1 within `foo&apos;</span>
<span class="token comment"># define double @julia_foo_846(i64, double) {</span>
<span class="token comment"># top:</span>
<span class="token comment"># ; &#x250C; @ promotion.jl:311 within `+&apos;</span>
<span class="token comment"># ; &#x2502;&#x250C; @ promotion.jl:282 within `promote&apos;</span>
<span class="token comment"># ; &#x2502;&#x2502;&#x250C; @ promotion.jl:259 within `_promote&apos;</span>
<span class="token comment"># ; &#x2502;&#x2502;&#x2502;&#x250C; @ number.jl:7 within `convert&apos;</span>
<span class="token comment"># ; &#x2502;&#x2502;&#x2502;&#x2502;&#x250C; @ float.jl:60 within `Float64&apos;</span>
<span class="token comment">#        %2 = sitofp i64 %0 to double</span>
<span class="token comment"># ; &#x2502;&#x2514;&#x2514;&#x2514;&#x2514;</span>
<span class="token comment"># ; &#x2502; @ promotion.jl:311 within `+&apos; @ float.jl:401</span>
<span class="token comment">#    %3 = fadd double %2, %1</span>
<span class="token comment"># ; &#x2514;</span>
<span class="token comment">#   ret double %3</span>
<span class="token comment"># }</span>
</pre><p>Yes, it looks like it does a little bit more, but still there is no type checking here, it is, just like a handwritten C code, perfectly optimized for the specific types.</p>
<p>so each time that you change the types that are going to your function, there is a different function that&apos;s compiled. If we change the values keeping the types same, we have the same function.</p>
<p>Now restart the REPL and try</p>
<pre data-role="codeBlock" data-info="julia" class="language-julia"><span class="token comment"># code chunk 8</span>
f<span class="token punctuation">(</span>x<span class="token punctuation">,</span>y<span class="token punctuation">)</span> <span class="token operator">=</span> x<span class="token operator">+</span>y
@time @code_llvm foo<span class="token punctuation">(</span><span class="token number">2.0</span><span class="token punctuation">,</span><span class="token number">8.0</span><span class="token punctuation">)</span>
@time @code_llvm foo<span class="token punctuation">(</span><span class="token number">2.0</span><span class="token punctuation">,</span><span class="token number">5.0</span><span class="token punctuation">)</span> 
</pre><p>So what happens when you call a function (with the same types) multiple times? First time it compiles, and then when you execute this for the second time (or maybe more), it already compiled this. So it just uses the same information again and runs it. So  type information is a compile time information, and then the <strong>actual value</strong> of the floating point numbers is a runtime information you can specialize on the type information, but you cannot specialize the function on the runtime information and so the way that julia then works here is that because it uses type information, it makes things fast (similar to C). When you give a combination of functions, it will do the same thing, but will do it for one level more. Let&apos;s also check with <code>@code_typed</code></p>
<pre data-role="codeBlock" data-info="julia" class="language-julia">@code_typed foo<span class="token punctuation">(</span><span class="token number">2.0</span><span class="token punctuation">,</span> <span class="token number">8.0</span><span class="token punctuation">)</span>
</pre><p>You see <code>Float64</code> so it automatically recognizes.</p>
<p>Now, if it <em>cannot figure out the type</em> in that case what we have is called <strong>type-instability</strong>. We can use the <code>@code_warntype</code> macro to better see the inference along the steps of the function:</p>
<pre data-role="codeBlock" data-info="julia" class="language-julia">foo<span class="token punctuation">(</span>x <span class="token punctuation">,</span> y<span class="token punctuation">)</span> <span class="token operator">=</span> x <span class="token operator">+</span> y
@code_warntype foo<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">5.0</span><span class="token punctuation">)</span>
@code_warntype foo<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span>
</pre><p>This is a very useful macro to detect the type-instability in your code.</p>
<h2 class="mume-header" id="type-stability">Type Stability</h2>

<p>When successful type inference happens at compile time, we call the function a <code>type-stable</code> function. Does type inference always happen smoothly? Or more importantly we may ask when does it fail? Here is an example,</p>
<pre data-role="codeBlock" data-info="julia" class="language-julia"><span class="token keyword">function</span> h<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span>
    out <span class="token operator">=</span> x <span class="token operator">+</span> y
    rand<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&lt;</span> <span class="token number">0.5</span> <span class="token punctuation">?</span> out <span class="token punctuation">:</span> Float64<span class="token punctuation">(</span>out<span class="token punctuation">)</span>
<span class="token keyword">end</span>


julia<span class="token operator">&gt;</span> @code_warntype h<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span>
<span class="token comment"># Variables</span>
<span class="token comment">#   #self#::Core.Compiler.Const(h, false)</span>
<span class="token comment">#   x::Int64</span>
<span class="token comment">#   y::Int64</span>
<span class="token comment">#   out::Int64</span>

<span class="token comment"># Body::Union{Float64, Int64}</span>
<span class="token comment"># 1 &#x2500;      (out = x + y)</span>
<span class="token comment"># &#x2502;   %2 = Main.rand()::Float64</span>
<span class="token comment"># &#x2502;   %3 = (%2 &lt; 0.5)::Bool</span>
<span class="token comment"># &#x2514;&#x2500;&#x2500;      goto #3 if not %3</span>
<span class="token comment"># 2 &#x2500;      return out</span>
<span class="token comment"># 3 &#x2500; %6 = Main.Float64(out)::Float64</span>
<span class="token comment"># &#x2514;&#x2500;&#x2500;      return %6</span>


</pre><p>Look at the thing in red. Here, on an integer input the output&apos;s type is randomly either <code>Int</code>or <code>Float64</code>, and thus the output is unknown at compile time. How can we change this function to a  <code>type-stable</code> (and also another function), maybe we write <code>1 &lt; 2</code> in place of <code>rand() &lt; 0.5</code></p>
<pre data-role="codeBlock" data-info="julia" class="language-julia"><span class="token comment"># code chunk 17</span>
<span class="token keyword">function</span> h2<span class="token punctuation">(</span>x<span class="token punctuation">,</span>y<span class="token punctuation">)</span>
    out <span class="token operator">=</span> x <span class="token operator">+</span> y
    <span class="token number">1</span> <span class="token operator">&lt;</span> <span class="token number">2</span> <span class="token punctuation">?</span> out <span class="token punctuation">:</span> Float64<span class="token punctuation">(</span>out<span class="token punctuation">)</span>
<span class="token keyword">end</span>

julia<span class="token operator">&gt;</span> @code_warntype h2<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span>
<span class="token comment"># Variables</span>
<span class="token comment">#   #self#::Core.Compiler.Const(h2, false)</span>
<span class="token comment">#   x::Int64</span>
<span class="token comment">#   y::Int64</span>
<span class="token comment">#   out::Int64</span>

<span class="token comment"># Body::Int64</span>
<span class="token comment"># 1 &#x2500;      (out = x + y)</span>
<span class="token comment"># &#x2502;   %2 = (1 &lt; 2)::Core.Compiler.Const(true, false)</span>
<span class="token comment"># &#x2502;        %2</span>
<span class="token comment"># &#x2514;&#x2500;&#x2500;      return out</span>
<span class="token comment"># 2 &#x2500;      Core.Compiler.Const(:(Main.Float64(out)), false)</span>
<span class="token comment"># &#x2514;&#x2500;&#x2500;      Core.Compiler.Const(:(return %5), false</span>
</pre><p>Looks fine, can we see something from <code>@code_llvm</code> for the type unstable function.</p>
<h2 class="mume-header" id="compilation-pipeline">Compilation pipeline</h2>

<p>Now we can try to understand the compilation pipleline, and hopefully things will make more sense.</p>
<img title="Random Walks" src="img/Julia_CompilationPipeline.png" alt="random walk" style="width:600px; height:400px;">
<p>What Lionel explained is why some people say that Julia has a just ahead of time compiler. So let&apos;s try to see what this means with the compilation pipeline of Julia. So when we are executing a Julia code,</p>
<ul>
<li>
<p>It all begins with the source code,</p>
</li>
<li>
<p>Source code is parsed and then macro expanded and this is all done from an AST (Abstract Syntax Tree, lets see some picture) which is a Julia object of type <code>exp</code> (recall expression)</p>
</li>
<li>
<p>Then this expression is lowered to an internal representation (IR) and as you can see, that we can access the different stages of compilation using different macros.</p>
</li>
<li>
<p>Once code has been loaded into memory runtime can begins and runtime consists in a very simple loop,</p>
</li>
<li>
<p>You have a function call and this function is <strong>dispatched</strong> and then you get a method which is executed and which will probably call another method and so on.</p>
</li>
<li>
<p>Now the interesting part is what happens during the dispatch.</p>
</li>
<li>
<p>Julia <strong>specializes the method you have dispatched on according to the concrete types of all of the arguments</strong>.</p>
</li>
<li>
<p>So when you&apos;re dispatching either you have a concrete call where you already have in memory a specialized method for this particular call will be executed.</p>
</li>
<li>
<p>Otherwise you begin with a specialization cycle.</p>
</li>
<li>
<p>Specialization takes the internal representation that was loaded in memory of the method it was dispatched on and begins with <strong>type inference</strong> which is a <em>dataflow analysis that propagates the types so the concrete types from those from the signature through the body of the function</em>.</p>
</li>
<li>
<p>What can happen during this stage is that maybe you have another call within this method you&apos;re compiling and if type inference is good enough in your case you may be able to infer the concrete types of all of the arguments to this new call.</p>
</li>
<li>
<p>In that case you already know <strong>at compile time what method this particular function call will be dispatched on</strong>.</p>
</li>
<li>
<p>As a consequence you can already launch another specialization cycle, this is the reason for the back arrow here.</p>
</li>
<li>
<p>Once code has been typed, after than it goes through a series transformation.</p>
</li>
<li>
<p>Finally after code is optimized it is translated to LLVM that generates native code</p>
</li>
<li>
<p>Once we have native code it is stored in memory for in the method table of the function so that next time the same function call the function call with the same causing signature happens it can be directly the specialized</p>
</li>
</ul>
<p>Let&apos;s see an example of a type-stable code,</p>
<pre data-role="codeBlock" data-info="julia" class="language-julia"><span class="token keyword">function</span> intlog2<span class="token punctuation">(</span>n<span class="token punctuation">)</span> <span class="token comment"># n::Int64</span>
    r <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token comment"># n::Int64</span>
    <span class="token keyword">while</span> n <span class="token operator">&gt;</span> <span class="token number">1</span>
        <span class="token comment"># n::Int64</span>
        r <span class="token operator">+=</span> <span class="token number">1</span>
        <span class="token comment"># n::Int64</span>
        n <span class="token operator">=</span> n<span class="token operator">/</span><span class="token number">2</span>
        <span class="token comment"># n::Float64</span>
    <span class="token keyword">end</span>
    <span class="token keyword">return</span> r
<span class="token keyword">end</span>
</pre><p>2nd loop</p>
<pre data-role="codeBlock" data-info="julia" class="language-julia"><span class="token keyword">function</span> intlog2<span class="token punctuation">(</span>n<span class="token punctuation">)</span> <span class="token comment"># n::Int64</span>
    r <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token keyword">while</span> n <span class="token operator">&gt;</span> <span class="token number">1</span>
        <span class="token comment"># n::Union{Int64, Float64}</span>
        r <span class="token operator">+=</span> <span class="token number">1</span>
        <span class="token comment"># n::Union{Int64, Float64}</span>
        n <span class="token operator">=</span> n<span class="token operator">/</span><span class="token number">2</span>
        <span class="token comment"># n::Union{Int64, Float64}</span>
    <span class="token keyword">end</span>
    <span class="token keyword">return</span> r
<span class="token keyword">end</span>
</pre><p>the type of <code>n</code> outside the loop will be <code>Union{Int64, Float64}</code> because it is possible that we never entered the loop. All the variables are also inferred in the type inference, so we will get</p>
<pre data-role="codeBlock" data-info="julia" class="language-julia"><span class="token keyword">function</span> intlog2<span class="token punctuation">(</span>n<span class="token punctuation">)</span> <span class="token comment"># n::Int64</span>
    r <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token keyword">while</span> n <span class="token operator">&gt;</span> <span class="token number">1</span>
        <span class="token comment"># n::Union{Int64, Float64}, r::Int64</span>
        r <span class="token operator">+=</span> <span class="token number">1</span>
        <span class="token comment"># n::Union{Int64, Float64}, r::Int64</span>
        n <span class="token operator">=</span> n<span class="token operator">/</span><span class="token number">2</span>
        <span class="token comment"># n::Union{Int64, Float64}, r::Int64</span>
    <span class="token keyword">end</span>

    <span class="token keyword">return</span> r <span class="token comment"># r::Int64</span>
<span class="token keyword">end</span>
</pre><p>So at the end we know that return type of this method will be always <code>Int64</code>. As a consequence this is what we say a <code>type-stable</code> method. Meaning compiler could perfectly infer the types. If this function is called again, it will just reuse this information.</p>
<h2 class="mume-header" id="boxing-and-unboxing">Boxing and Unboxing</h2>

<p>This is from Steve Johnson&apos;s lecture and also from Lionel&apos;s presentation.</p>
<img title="Random Walks" src="img/Julia_boxing.png" alt="random walk" style="width:600px; height:400px;">
<p>You are just dead. Julia unboxes</p>
<img title="Random Walks" src="img/Julia_unboxing2.png" alt="random walk" style="width:600px; height:190px;">
<p>Why this is useful. This explains why julia is faster for loops rather than vectorization.</p>
<h2 class="mume-header" id="references">References</h2>

<ul>
<li>
<p>There is wonderful lecture series from Chris Rackaukas, <a href="https://www.youtube.com/watch?v=3IoqyXmAAkU&amp;list=PLCAl7tjCwWyGjdzOOnlbGnVNZk0kB8VSa&amp;index=1">Youtube link</a>. Click on the link. The course also has many other things which you can use to learn if you are interested. I learned many things from here.</p>
</li>
<li>
<p><a href="https://www.youtube.com/watch?v=XWIZ_dCO6X8&amp;t=1204s">Presentation of Lionel Zoubritzky</a> at JuliaCon. I think the very first presentation which went to this depth.</p>
</li>
<li>
<p><a href="https://www.youtube.com/watch?v=6JcMuFgnA6U&amp;t=218s">Steve Johonson&apos;s presentation for the course - MIT 6.172 Performance Engineering of Software Systems, Fall 2018</a>. The course is also a fantastic course, but more towards theory, here is the <a href="https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-172-performance-engineering-of-software-systems-fall-2018/">page</a>. All video lectures are available at MIT OCW.</p>
</li>
<li>
<p><a href="https://medium.com/android-news/magic-lies-here-statically-typed-vs-dynamically-typed-languages-d151c7f95e2b#:~:text=Static%20typed%20languages,%2C%20FORTRAN%2C%20Pascal%20and%20Scala">Magic lies here - Statically vs Dynamically Typed Languages</a> . There are 100s of article like this. But I must admit this was good. So I added some stuffs from here.</p>
</li>
<li>
<p>Sengupta, A., &amp; Edelman, A. (2019). Julia High Performance: Optimizations, distributed computing, multithreading, and GPU programming with Julia 1.0 and beyond, 2nd Edition. Packt Publishing.</p>
</li>
<li>
<p>Kwong, T., &amp; Karpinski, S. (2020). Hands-On Design Patterns and Best Practices with Julia: Proven solutions to common problems in software design for Julia 1.x. Packt Publishing.</p>
</li>
</ul>
<p>I think the above two books by Packt I really liked and read some parts. Probably I will take some parts from there for the coming sections as well. Problems is Julia changed so much so many books have become outdated, so these are relatively the recent ones and also quite well written. I am sorry honestly, even if I didn&apos;t want to, some of the references I unintentionally missed, which happened out of hurry. But I should be more careful as I mentioned, <strong>this is serious stuff!</strong>. So I better be more careful. But if you think, if I missed anything and you are able catch me, feel free to let me know, I will consider this as a favor. Since I honestly believe this is a bad practice, I will be really happy. The people should be recognized for what they have done. But finally I hope now it is ok, and I am not missing my references.</p>

      </div>
      
      
    
    
    
    
    
    
    
    
  
    </body></html>